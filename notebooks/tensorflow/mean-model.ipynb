{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow: Mean model\n",
    "\n",
    "Implement mean model (always predict mean value) in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import calendar\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Input Data \n",
    "\n",
    "## Load and clean data\n",
    "\n",
    "Load rainfall and flow data from the files and clean it by:\n",
    "  * Resampling to 5 minutes\n",
    "  * Slice to the common range\n",
    "  * Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           flow  rainfall\n",
      "time                                     \n",
      "2015-06-01 14:15:00  115.559998       0.0\n",
      "2015-06-01 14:20:00  115.199997       0.0\n",
      "2015-06-01 14:25:00  112.209999       0.0\n",
      "2015-06-01 14:30:00  112.860001       0.0\n",
      "2015-06-01 14:35:00  113.349998       0.0\n",
      "                           flow  rainfall\n",
      "time                                     \n",
      "2017-11-10 14:20:00  107.830002       0.0\n",
      "2017-11-10 14:25:00  107.459999       0.0\n",
      "2017-11-10 14:30:00  106.919998       0.0\n",
      "2017-11-10 14:35:00  105.559998       0.0\n",
      "2017-11-10 14:40:00  104.940002       0.0\n"
     ]
    }
   ],
   "source": [
    "project_folder = '../../datasets/thorium-medium/'\n",
    "flow = pd.read_csv(project_folder + 'flow1.csv', parse_dates=['time'])\n",
    "flow = flow.set_index('time')['flow'].fillna(0)\n",
    "flow = flow.resample('5T').pad()\n",
    "rainfall = pd.read_csv(project_folder + 'rainfall1.csv', parse_dates=['time'])\n",
    "rainfall = rainfall.set_index('time')['rainfall'].fillna(0)\n",
    "rainfall = rainfall.resample('5T').pad()\n",
    "flow_rain = pd.concat([flow, rainfall], axis=1).dropna()\n",
    "print(flow_rain.head())\n",
    "print(flow_rain.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process DateTime column\n",
    "\n",
    "DateTime can be used to construct feature vector. But to allow working with dates in TensorFlow we need to convert it to separate fields:\n",
    "  * year\n",
    "  * day of year\n",
    "  * minute of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>minute</th>\n",
       "      <th>flow</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-01 14:15:00</th>\n",
       "      <td>152</td>\n",
       "      <td>855</td>\n",
       "      <td>115.559998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-01 14:20:00</th>\n",
       "      <td>152</td>\n",
       "      <td>860</td>\n",
       "      <td>115.199997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-01 14:25:00</th>\n",
       "      <td>152</td>\n",
       "      <td>865</td>\n",
       "      <td>112.209999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-01 14:30:00</th>\n",
       "      <td>152</td>\n",
       "      <td>870</td>\n",
       "      <td>112.860001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-01 14:35:00</th>\n",
       "      <td>152</td>\n",
       "      <td>875</td>\n",
       "      <td>113.349998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     day  minute        flow  rainfall\n",
       "time                                                  \n",
       "2015-06-01 14:15:00  152     855  115.559998       0.0\n",
       "2015-06-01 14:20:00  152     860  115.199997       0.0\n",
       "2015-06-01 14:25:00  152     865  112.209999       0.0\n",
       "2015-06-01 14:30:00  152     870  112.860001       0.0\n",
       "2015-06-01 14:35:00  152     875  113.349998       0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_rain['day'] = flow_rain.index.map(lambda x : x.dayofyear)\n",
    "flow_rain['minute'] = flow_rain.index.map(lambda x : x.hour*60 + x.minute)\n",
    "input_data = flow_rain[['day', 'minute', 'flow', 'rainfall']]\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions working on Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     minute  day\n",
      "time                            \n",
      "2016-11-09 23:35:00    1415  314\n",
      "2016-11-09 23:40:00    1420  314\n",
      "2016-11-09 23:45:00    1425  314\n",
      "2016-11-09 23:50:00    1430  314\n",
      "2016-11-09 23:55:00    1435  314\n",
      "                     minute  day\n",
      "time                            \n",
      "2016-11-10 00:00:00       0  315\n",
      "2016-11-10 00:05:00       5  315\n",
      "2016-11-10 00:10:00      10  315\n",
      "2016-11-10 00:15:00      15  315\n",
      "2016-11-10 00:20:00      20  315\n",
      "                     minute  day\n",
      "time                            \n",
      "2016-11-10 23:35:00    1415  315\n",
      "2016-11-10 23:40:00    1420  315\n",
      "2016-11-10 23:45:00    1425  315\n",
      "2016-11-10 23:50:00    1430  315\n",
      "2016-11-10 23:55:00    1435  315\n"
     ]
    }
   ],
   "source": [
    "def split_data(df_features, df_labels, split_day):\n",
    "    \"\"\"Split data into dataframe before given day and with the given day\"\"\"\n",
    "    end_day = split_day - pd.Timedelta('1 min')\n",
    "    next_day = split_day + pd.Timedelta('1439 min')\n",
    "    return df_features[:end_day], df_labels[:end_day], df_features[split_day: next_day], df_labels[split_day: next_day]\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_data(input_data[['minute', 'day']], input_data.flow, pd.Timestamp('2016-11-10'))\n",
    "print(x_train.tail())\n",
    "print(x_test.head())\n",
    "print(x_test.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TensorFlow graph\n",
    "\n",
    "## Error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.33333333333333\n"
     ]
    }
   ],
   "source": [
    "def calculate_error_op(y_hat, y):\n",
    "    \"\"\"\n",
    "    Create operation for calculating https://en.wikipedia.org/wiki/Mean_absolute_percentage_error\n",
    "    \"\"\"\n",
    "    score_op = 100 * tf.reduce_mean(tf.abs((y-y_hat) / y))\n",
    "    return score_op\n",
    "\n",
    "# The value should be ~43.3(3)%\n",
    "with tf.Session() as sess:\n",
    "    op = calculate_error_op(tf.constant([1,2,3]), tf.constant([1,5,10]))\n",
    "    print(sess.run(op))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define TensorFlow graph\n",
    "\n",
    "Define base prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]]\n",
      "Calculated in 0.908 seconds\n"
     ]
    }
   ],
   "source": [
    "class MeanModel:\n",
    "    \"\"\"\n",
    "    This model always predicts mean value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        model - tensor consists of mean value\n",
    "        \"\"\"\n",
    "        self.features = tf.placeholder(tf.float32, shape=(None, None))\n",
    "        self.labels = tf.placeholder(tf.float32, shape=(None))\n",
    "        self.model = tf.Variable([0.0])\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Create train operation.\n",
    "        Params:\n",
    "        x - Tensor with features\n",
    "        y - Tensor with labels\n",
    "        \"\"\"\n",
    "        mean = tf.reshape(tf.reduce_mean(self.labels), [1])\n",
    "        assign_op = self.model.assign(mean)\n",
    "        return assign_op\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Create predict operation. It returns labels based on a given features\n",
    "        \"\"\"\n",
    "        f = lambda _: self.model\n",
    "        predict_op = tf.map_fn(f, self.features)\n",
    "        return predict_op\n",
    "    \n",
    "    def loss(self):\n",
    "        \"\"\"\n",
    "        Calculate prediction loss\n",
    "        \"\"\"\n",
    "        predict_op = self.predict()\n",
    "        error_op = calculate_error_op(predict_op, self.labels)\n",
    "        return error_op\n",
    "\n",
    "    \n",
    "# Expected [[2.] [2.]]\n",
    "model = MeanModel()\n",
    "train_op = model.train()\n",
    "predict_op = model.predict()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    features = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    labels = np.array([1.0, 2.0, 3.0])\n",
    "    start_time = time.time()\n",
    "    sess.run(train_op, feed_dict={model.features: features, model.labels: labels})\n",
    "    print(sess.run(predict_op, feed_dict={model.features: features}))\n",
    "    print(\"Calculated in {:.3f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 98.95%\n",
      "Calculated in 5.835 seconds\n"
     ]
    }
   ],
   "source": [
    "def evaluate_day(sess, model, X, y, split_day):\n",
    "    \"\"\"Evaluate data for single day\"\"\"\n",
    "    train_op = model.train()\n",
    "    predict_op = model.predict()\n",
    "    loss_op = model.loss()\n",
    "    x_train, y_train, x_test, y_test = split_data(X, y, split_day)\n",
    "    sess.run(train_op, feed_dict={model.features: x_train, model.labels: y_train})\n",
    "    error = sess.run(loss_op, feed_dict={model.features: x_test, model.labels: y_test})\n",
    "    return error\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y, start_day):\n",
    "    \"\"\"\n",
    "    Evaluate model on all days starting from the split_day.\n",
    "    Returns 95th percentile error as model score\n",
    "    \"\"\"\n",
    "    last_day = flow.index[-1] - pd.Timedelta(1, 'D')\n",
    "    split_day = start_day\n",
    "    costs = []\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    while split_day < last_day:\n",
    "        cost = evaluate_day(sess, model, X, y, split_day)\n",
    "        costs.append(cost)\n",
    "        split_day += pd.Timedelta(1, 'D')\n",
    "    return np.percentile(costs, 95), costs\n",
    "\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    error = evaluate_day(sess, MeanModel(), input_data[['day', 'minute']], input_data.flow, pd.Timestamp('2016-11-10'))\n",
    "    print('Error: {:.2f}%'.format(error))\n",
    "print(\"Calculated in {:.3f} seconds\".format(time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models for year 2017\n",
    "\n",
    "Now when we have all functions ready we will evaluate model for each day of the 2017 year. \n",
    "And then report 95th percentile as a model error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanModel 95th percentile error: 22.68%\n",
      "Calculated in 577.533 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "score, costs = evaluate_model(MeanModel(), input_data[['day', 'minute']], input_data.flow, pd.Timestamp('2017-01-01'))\n",
    "print('MeanModel 95th percentile error: {:.2f}%'.format(score))\n",
    "print(\"Calculated in {:.3f} seconds\".format(time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
